import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv(r"Desktop/sales_data_sample.csv", encoding='ISO-8859-1')

# Display the first few rows and column names to understand the structure
print("First few rows of the dataset:")
print(df.head())
print("Column names in the dataset:")
print(df.columns)

# Define numeric columns for clustering
numeric_cols = ['QUANTITYORDERED', 'PRICEEACH', 'SALES']

# Check if 'SALES' exists, and if not, calculate it
if 'SALES' not in df.columns:
    print("Column 'SALES' not found, calculating as 'QUANTITYORDERED' * 'PRICEEACH'.")
    df['SALES'] = df['QUANTITYORDERED'] * df['PRICEEACH']

# Now check if all numeric columns are available
missing_cols = [col for col in numeric_cols if col not in df.columns]
if missing_cols:
    raise KeyError(f"Columns {missing_cols} not found in the dataset. Available columns: {df.columns.tolist()}")

# Convert selected columns to numeric, forcing errors to NaN
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')

# Check the data types of the selected columns to confirm conversion
print("Data types after conversion:")
print(df[numeric_cols].dtypes)

# Handle missing values by filling them with the mean of the respective column
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

# Scale the features
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df[numeric_cols])

# Determine the optimal number of clusters using the elbow method
wcss = []  # Within-cluster sum of squares
for i in range(1, 11):  # Try clusters from 1 to 10
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)
    kmeans.fit(scaled_data)
    wcss.append(kmeans.inertia_)

# Plot the elbow graph
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

# Based on the elbow method, choose the optimal k (e.g., 3 here)
k = 3

# Apply K-Means clustering with the chosen number of clusters
kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)
y_kmeans = kmeans.fit_predict(scaled_data)

# Add the cluster labels to the original dataset
df['Cluster'] = y_kmeans

# Display the first few rows with the cluster assignments
print("Dataset with cluster assignments:")
print(df.head())

# Visualize the clusters in a 2D plot (using the first two columns for visualization)
plt.scatter(scaled_data[:, 0], scaled_data[:, 1], c=y_kmeans, s=50, cmap='viridis')
plt.title(f'K-Means Clustering (k={k})')
plt.xlabel(numeric_cols[0])
plt.ylabel(numeric_cols[1])
plt.show()